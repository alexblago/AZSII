{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Практическая работа №6.\n",
        "## Выполнил студент Благоразумов Александр Сергеевич группы ББМО-01-23"
      ],
      "metadata": {
        "id": "WBva67F7nBwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Загрузка и создание двух различных моделей\n"
      ],
      "metadata": {
        "id": "-e4OTRgAoJUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Загрузка данных MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Нормализация данных\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Преобразование меток в one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Модель 1: Простая полносвязная нейронная сеть\n",
        "model1 = Sequential([\n",
        "  Flatten(input_shape=(28, 28)),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dense(10, activation='softmax')])\n",
        "\n",
        "# Компиляция модели\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model1.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Сохранение модели\n",
        "model1.save('mnist_model1.h5')\n",
        "\n",
        "# Модель 2: Свёрточная нейронная сеть (CNN)\n",
        "model2 = Sequential([\n",
        "  Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  MaxPooling2D((2, 2)),\n",
        "  Flatten(),\n",
        "  Dense(128, activation='relu'),\n",
        "  Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
        "\n",
        "# Сохранение модели\n",
        "model2.save('mnist_model2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rksl8JDFoRcY",
        "outputId": "e9e7de81-254d-4425-b4da-d38e781836ef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8741 - loss: 0.4407\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1211\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0797\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0598\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 22ms/step - accuracy: 0.9180 - loss: 0.2898\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 21ms/step - accuracy: 0.9856 - loss: 0.0504\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 21ms/step - accuracy: 0.9906 - loss: 0.0293\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 22ms/step - accuracy: 0.9944 - loss: 0.0189\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 22ms/step - accuracy: 0.9960 - loss: 0.0129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Реализация атаки FGSM на первую модель"
      ],
      "metadata": {
        "id": "LzpoLFhlsw-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Функция FGSM атаки\n",
        "def fgsm_attack(image, epsilon, gradient):\n",
        "\n",
        "  # Применение знака градиента к изображению\n",
        "  perturbed_image = image + epsilon * np.sign(gradient)\n",
        "  perturbed_image = np.clip(perturbed_image, 0, 1)\n",
        "  return perturbed_image\n",
        "\n",
        "# Генерация противоречивых примеров для первой модели\n",
        "def generate_adversarial_example(model, image, label, epsilon):\n",
        "    image = tf.convert_to_tensor(image.reshape((1, 28, 28, 1)))\n",
        "\n",
        "    # Если label — это one-hot вектор, то преобразуем его в индекс\n",
        "    if len(label.shape) > 1 and label.shape[1] > 1:\n",
        "        label = np.argmax(label)\n",
        "    label = tf.convert_to_tensor(label)\n",
        "\n",
        "    # Вычисление градиента\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        prediction = model(image)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n",
        "    gradient = tape.gradient(loss, image)\n",
        "\n",
        "    # Применяем FGSM\n",
        "    adversarial_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n",
        "    return np.reshape(adversarial_image, (28, 28, 1))\n",
        "def generate_adversarial_dataset(model, images, labels, epsilon):\n",
        "    adversarial_images = []\n",
        "    for i in range(len(images)):\n",
        "        adv_image = generate_adversarial_example(model, images[i], labels[i], epsilon)\n",
        "        adversarial_images.append(adv_image.reshape(28, 28))\n",
        "    adversarial_images = np.array(adversarial_images)\n",
        "    print(\"Shape of adversarial_images:\", adversarial_images.shape)\n",
        "    return adversarial_images\n",
        "\n",
        "# Генерация противоречивых примеров для первой модели\n",
        "epsilon = 0.1\n",
        "adversarial_images_model1 = generate_adversarial_dataset(model1, test_images, test_labels, epsilon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_674kWxs4WB",
        "outputId": "29e1e609-481e-4d4e-a36e-b05d1e982ddc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of adversarial_images: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Оценка противоречивых примеров на обеих моделях"
      ],
      "metadata": {
        "id": "SfKjoD_cuOxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка первой модели на противоречивых примерах\n",
        "loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples: {acc1}')\n",
        "\n",
        "# Оценка второй модели на противоречивых примерах (перенос атаки)\n",
        "adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1, 28, 28, 1)\n",
        "loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped, test_labels)\n",
        "print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWsvh9F6uSYa",
        "outputId": "1efcae9f-765c-425e-fa9f-4318951b9a0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0941 - loss: 6.6837\n",
            "Accuracy of model1 on adversarial examples: 0.12540000677108765\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.1486\n",
            "Accuracy of model2 on adversarial examples from model1: 0.9623000025749207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Анализ переносимости атак"
      ],
      "metadata": {
        "id": "pv3hFcrCub-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация противоречивых примеров для второй модели\n",
        "adversarial_images_model2 = generate_adversarial_dataset(model2,\n",
        "test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n",
        "\n",
        "# Оценка первой модели на противоречивых примерах второй модели\n",
        "loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28,\n",
        "28), test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7aMsQESueot",
        "outputId": "3b321924-8e12-4671-aa51-94a652f632f4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of adversarial_images: (10000, 28, 28)\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8502 - loss: 0.4668\n",
            "Accuracy of model1 on adversarial examples from model2: 0.8733999729156494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Вывод\n",
        "\n",
        "Подводя итоги мы видим, что первая модель, для которой были сгенерированы противоречивые примеры с использованием метода FGSM, продемонстрировала значительное снижение точности, что указывает на её высокую уязвимость к данной атаке. В то же время вторая модель оказалась менее подверженной воздействию FGSM-атак: её точность снизилась незначительно, что свидетельствует о большей устойчивости к переносу атак, созданных для другой модели.\n",
        "\n",
        "Полученные результаты показывают, что атаки по переносу с использованием FGSM могут значительно снижать точность модели, особенно если атакующие примеры генерировались для неё. Однако модели с более высокой устойчивостью сохраняют точность даже при воздействии таких атак. Это подчёркивает необходимость разработки более устойчивых моделей, способных противостоять атакам, перенесённым с других систем."
      ],
      "metadata": {
        "id": "zN8aOy7putyE"
      }
    }
  ]
}